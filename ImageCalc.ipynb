{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"G:/ml notebooks/Road_RUL/datasets/runs/detect/train3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 G:\\ml notebooks\\Road_RUL\\datasets\\all_images\\China_MotorBike_000950.jpg: 640x640 3 D40s, 13.0ms\n",
      "Speed: 6.0ms preprocess, 13.0ms inference, 141.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      "1 label saved to runs\\detect\\predict3\\labels\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(source=\"G:/ml notebooks/Road_RUL/datasets/all_images/China_MotorBike_000950.jpg\",save=True,save_txt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'D00', 1: 'D40', 2: 'D10', 3: 'D20', 4: 'Repair', 5: 'Block crack', 6: 'D44', 7: 'D43', 8: 'D01', 9: 'D11', 10: 'D50', 11: 'D0w0'}\n",
       "orig_img: array([[[160, 155, 152],\n",
       "        [155, 150, 147],\n",
       "        [148, 143, 140],\n",
       "        ...,\n",
       "        [127, 123, 122],\n",
       "        [133, 129, 128],\n",
       "        [130, 126, 125]],\n",
       "\n",
       "       [[164, 159, 156],\n",
       "        [153, 148, 145],\n",
       "        [144, 139, 136],\n",
       "        ...,\n",
       "        [126, 122, 121],\n",
       "        [128, 124, 123],\n",
       "        [124, 120, 119]],\n",
       "\n",
       "       [[163, 158, 155],\n",
       "        [151, 146, 143],\n",
       "        [146, 141, 138],\n",
       "        ...,\n",
       "        [128, 124, 123],\n",
       "        [130, 126, 125],\n",
       "        [126, 122, 121]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[134, 133, 135],\n",
       "        [153, 152, 154],\n",
       "        [157, 156, 158],\n",
       "        ...,\n",
       "        [143, 142, 146],\n",
       "        [188, 187, 191],\n",
       "        [223, 222, 226]],\n",
       "\n",
       "       [[106, 105, 107],\n",
       "        [161, 160, 162],\n",
       "        [209, 208, 210],\n",
       "        ...,\n",
       "        [128, 127, 131],\n",
       "        [160, 159, 163],\n",
       "        [184, 183, 187]],\n",
       "\n",
       "       [[160, 159, 161],\n",
       "        [153, 152, 154],\n",
       "        [163, 162, 164],\n",
       "        ...,\n",
       "        [160, 159, 163],\n",
       "        [130, 129, 133],\n",
       "        [186, 185, 189]]], dtype=uint8)\n",
       "orig_shape: (512, 512)\n",
       "path: 'G:\\\\ml notebooks\\\\Road_RUL\\\\datasets\\\\all_images\\\\China_MotorBike_000950.jpg'\n",
       "probs: None\n",
       "save_dir: 'runs\\\\detect\\\\predict3'\n",
       "speed: {'preprocess': 6.028890609741211, 'inference': 12.959003448486328, 'postprocess': 141.2346363067627}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[375.5027,  98.5197, 481.7326, 260.5540,   0.8525,   1.0000],\n",
       "        [237.2420, 227.6635, 318.4546, 511.3420,   0.7767,   1.0000],\n",
       "        [335.1393, 194.1595, 388.5824, 324.0883,   0.7674,   1.0000]], device='cuda:0')\n",
       "cls: tensor([1., 1., 1.], device='cuda:0')\n",
       "conf: tensor([0.8525, 0.7767, 0.7674], device='cuda:0')\n",
       "data: tensor([[375.5027,  98.5197, 481.7326, 260.5540,   0.8525,   1.0000],\n",
       "        [237.2420, 227.6635, 318.4546, 511.3420,   0.7767,   1.0000],\n",
       "        [335.1393, 194.1595, 388.5824, 324.0883,   0.7674,   1.0000]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (512, 512)\n",
       "shape: torch.Size([3, 6])\n",
       "xywh: tensor([[428.6176, 179.5368, 106.2300, 162.0344],\n",
       "        [277.8483, 369.5028,  81.2126, 283.6785],\n",
       "        [361.8609, 259.1238,  53.4431, 129.9288]], device='cuda:0')\n",
       "xywhn: tensor([[0.8371, 0.3507, 0.2075, 0.3165],\n",
       "        [0.5427, 0.7217, 0.1586, 0.5541],\n",
       "        [0.7068, 0.5061, 0.1044, 0.2538]], device='cuda:0')\n",
       "xyxy: tensor([[375.5027,  98.5197, 481.7326, 260.5540],\n",
       "        [237.2420, 227.6635, 318.4546, 511.3420],\n",
       "        [335.1393, 194.1595, 388.5824, 324.0883]], device='cuda:0')\n",
       "xyxyn: tensor([[0.7334, 0.1924, 0.9409, 0.5089],\n",
       "        [0.4634, 0.4447, 0.6220, 0.9987],\n",
       "        [0.6546, 0.3792, 0.7590, 0.6330]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need xyxy data but in pixels,not normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Our other model was unable to calculate RUL properly, After doing intense research into this topic and spending almost a month collecting and going through research papers and articles, I have found this approach quite simple to use and can easily find the RUL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy will be compromised for the sake of simplicity of this project, I will be mentioning what more can be done in Scope For Improvement section in Project Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_fetch(results):\n",
    "    #I have just made one single codeblock to get our results\n",
    "    # # Move the results to CPU\n",
    "    results = [result.cpu() for result in results]\n",
    "    lis=[]\n",
    "    # Convert the results to numpy\n",
    "    results = [result.numpy() for result in results]\n",
    "    # Get the bounding boxes\n",
    "    boxes = results[0].boxes\n",
    "    for box in boxes:\n",
    "        type_of_damage=results[0].names[box.cls[0]]\n",
    "        dpi=96\n",
    "        px_to_mm=25.4/dpi\n",
    "        # Get the bounding box in the format [x1, y1, x2, y2]Top Left and Bottom Right\n",
    "        bbox = box.xyxy[0]\n",
    "    \n",
    "        # Convert the bounding box coordinates to pixels\n",
    "        image_width = results[0].orig_img.shape[1]*px_to_mm\n",
    "        image_height = results[0].orig_img.shape[0]*px_to_mm\n",
    "    \n",
    "        x1 = bbox[0] * image_width\n",
    "        y1 = bbox[1] * image_height\n",
    "        x2 = bbox[2] * image_width\n",
    "        y2 = bbox[3] * image_height\n",
    "    \n",
    "        # Calculate the width and height of the bounding box\n",
    "        width = (x2 - x1)*px_to_mm\n",
    "        height = (y2 - y1)*px_to_mm\n",
    "    \n",
    "        width=width*px_to_mm\n",
    "        height=height*px_to_mm\n",
    "    \n",
    "        # Calculate the area covered by the bounding box\n",
    "        area = width * height\n",
    "        area=area*(px_to_mm**2)\n",
    "    \n",
    "        # Calculate the area taken up by the bounding box relative to the image\n",
    "        image_area = image_width * image_height\n",
    "    \n",
    "        relative_area = (area / image_area)\n",
    "        lis.append([type_of_damage,((width+height)/2),relative_area])\n",
    "        \n",
    "        \n",
    "    return lis\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distress Params\n",
    "- Severity Of Distress-> Average of width and height is taken to get a rough estimate of length of the crack which points towards severity roughly.\n",
    " If this average :\n",
    " <500: Very Slight(1) ,\n",
    " <800: Slight(2), \n",
    " <1200: Moderate(3)  \n",
    " <1500: Severe, \n",
    " 1500+:Very Severe(5)\n",
    "\n",
    "- Density Of Distress-> Relative area of the bounding box and the total area of the image itself,can be improved with a segmentation model\n",
    "If relative area:\n",
    "1-3 : Few(1)\n",
    "4-6 : Intermitent(2)\n",
    "7-10 : Frequent(3)\n",
    "11-14 : Extensive(4)\n",
    "15+ : Throughout(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the types of damages\n",
    "-Lets condense these down to Just Cracks and Others\n",
    "Withing Cracks, we have Linear and Alligator\n",
    "\n",
    ">D00,D01,D10,D11 are Linear Crack\n",
    "D20 is Alligator Crack\n",
    "D40,D43,D44 and etc are Others\n",
    "\n",
    "- Severity can be kind of calculated by the width or height to show how big it is and the density is the relative area, we add these and then multiply it with the Wi value, add them up to get PCI, from PCI, there is a direct relation or a general ranges where we can determine RUL. This is done in modify() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'D00',\n",
       " 1: 'D40',\n",
       " 2: 'D10',\n",
       " 3: 'D20',\n",
       " 4: 'Repair',\n",
       " 5: 'Block crack',\n",
       " 6: 'D44',\n",
       " 7: 'D43',\n",
       " 8: 'D01',\n",
       " 9: 'D11',\n",
       " 10: 'D50',\n",
       " 11: 'D0w0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify(lis):\n",
    "    finals=[]\n",
    "    for dmges in lis:\n",
    "    #Get crack_type\n",
    "        if dmges[0] in ['D00','D01','D10','D11']:\n",
    "            crack_type=\"linear\"\n",
    "        elif dmges[0]=='D20':\n",
    "            crack_type=\"alligator\"\n",
    "        else:\n",
    "            crack_type=\"other\"\n",
    "         \n",
    "        #Get severity rating    \n",
    "        if dmges[1]<=500:\n",
    "            severity_rating=1\n",
    "        elif dmges[1]>500 and dmges[1]<=800:\n",
    "            severity_rating=2\n",
    "        elif dmges[1]>800 and dmges[1]<=1200:\n",
    "            severity_rating=3\n",
    "        elif dmges[1]>1200 and dmges[1]<=1500:\n",
    "            severity_rating=4\n",
    "        else:\n",
    "            severity_rating=5\n",
    "        \n",
    "        #Get density_rating\n",
    "        if dmges[2]<=3:\n",
    "            density_rating=1\n",
    "        elif dmges[2]>3 and dmges[2]<=6:\n",
    "            density_rating=2\n",
    "        elif dmges[2]>6 and dmges[2]<=10:\n",
    "            density_rating=3\n",
    "        elif dmges[2]>10 and dmges[2]<=14:\n",
    "            density_rating=4\n",
    "        else:\n",
    "            density_rating=5\n",
    "        \n",
    "        finals.append([crack_type,severity_rating,density_rating])\n",
    "    return finals\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCI_Calc(finals):\n",
    "  dmi=0\n",
    "  \"\"\"Calculates the Pavement Condition Index (PCI) of a road section, condensed to linear, alligator, and other cracks, where the weights are reduced by a smaller factor.\n",
    "  Args:\n",
    "  A list of lists which contains the following for each damage detected:\n",
    "    severity rating: The severity of the damage, from 1 to 5.\n",
    "    crack_type: The type of crack, as a string, either \"linear\", \"alligator\", or \"other\".\n",
    "    density_rating: The density rating of the damage, from 1 to 5.\n",
    "\n",
    "  Returns:\n",
    "    The PCI value, a float between 0 and 100.\n",
    "  \"\"\"\n",
    "  for f in finals:\n",
    "    # Get the weight for the crack type.\n",
    "    weight = {\n",
    "      \"linear\": 2.7,\n",
    "      \"alligator\": 2.2,\n",
    "      \"other\": 1.5,\n",
    "      }.get(f[0])\n",
    "    # Calculate the Distress Manifestation Index (DMI).\n",
    "    dmi+=(f[1]+f[2])*weight\n",
    "\n",
    "\n",
    "  pci=100-dmi\n",
    "  return pci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 G:\\ml notebooks\\Road_RUL\\datasets\\all_images\\Czech_001876.jpg: 640x640 1 D40, 182.4ms\n",
      "Speed: 8.0ms preprocess, 182.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(source=\"G:/ml notebooks/Road_RUL/datasets/all_images/Czech_001876.jpg\",save=True,save_txt=False)\n",
    "pci_value=PCI_Calc(modify(output_fetch(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pci_value>70:\n",
    "    quality=\"Good and does not need improvement, Maintenance is not urgent\"\n",
    "elif pci_value<70 and pci_value>55:\n",
    "    quality=\"Fair but needs maintenace soon,scope for improvement present\"\n",
    "else:\n",
    "    quality=\"Need Maintenance, Poor Quality and less service life\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets find Remaining Service Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.038229809189364\n"
     ]
    }
   ],
   "source": [
    "RUL=4.1872*(np.log(pci_value))-14.117\n",
    "print(RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest value possible is when PCI is perfect i.e 100,then we get RUL as 5.2 which basically means no road should go without maintenance for more than 5 years, although the road might be useful, according to general predictive maintenance procedures, the results are not too far off."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "377b4f1831a451850bc17c54efaf717a72893efa61b3f0f3297db47fe115df50"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
